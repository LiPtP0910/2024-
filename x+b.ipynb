{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voltage: 1\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Voltage: 10\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Voltage: 11\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Voltage: 12\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Voltage: 13\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Voltage: 2\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Voltage: 3\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Voltage: 4\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Voltage: 5\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Voltage: 6\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Voltage: 7\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Voltage: 8\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Voltage: 9\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Train inputs shape: (52, 3950, 11)\n",
      "Train outputs shape: (52, 50, 11)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def load_resistor_data(data_dir):\n",
    "    # 創建一個字典來保存所有電阻和電壓的數據\n",
    "    data = {}\n",
    "    \n",
    "    # 遍歷每個電壓資料夾\n",
    "    for voltage_folder in os.listdir(data_dir):\n",
    "        voltage_path = os.path.join(data_dir, voltage_folder)\n",
    "        if os.path.isdir(voltage_path):\n",
    "            # 創建一個子字典來保存這個電壓下的所有電阻數據\n",
    "            data[voltage_folder] = {}\n",
    "            \n",
    "            # 遍歷該電壓資料夾中的所有電阻文件\n",
    "            for resistor_file in os.listdir(voltage_path):\n",
    "                resistor_path = os.path.join(voltage_path, resistor_file)\n",
    "                if resistor_file.endswith('.csv'):\n",
    "                    # 讀取CSV文件到一個DataFrame中\n",
    "                    resistor_data = pd.read_csv(resistor_path)\n",
    "                    \n",
    "                    # 將數據存入字典中\n",
    "                    resistor_name = os.path.splitext(resistor_file)[0]  # 獲取文件名（去掉擴展名）\n",
    "                    data[voltage_folder][resistor_name] = resistor_data\n",
    "                    \n",
    "    return data\n",
    "\n",
    "# 假設數據位於 /data/ 目錄中\n",
    "data_dir = 'C:\\\\Users\\\\walter\\\\OneDrive\\\\桌面\\\\收集\\\\2024大數據競賽\\\\2024-pre-train'\n",
    "resistor_data = load_resistor_data(data_dir)\n",
    "\n",
    "# 查看讀取的數據結構\n",
    "for voltage, resistors in resistor_data.items():\n",
    "    print(f\"Voltage: {voltage}\")\n",
    "    for resistor, df in resistors.items():\n",
    "        print(f\"  Resistor: {resistor}, Data shape: {df.shape}\")\n",
    "\n",
    "#print(resistor_data['1']['a'])\n",
    "import numpy as np\n",
    "\n",
    "def split_data_for_training(resistor_data):\n",
    "    train_inputs = []\n",
    "    train_outputs = []\n",
    "    \n",
    "    # 遍歷每個電壓資料夾\n",
    "    for voltage, resistors in resistor_data.items():\n",
    "        for resistor, df in resistors.items():\n",
    "            # 檢查數據是否有足夠的行數\n",
    "            if len(df) >= 4000:\n",
    "                # 前50筆數據作為輸入\n",
    "                input_data = df.iloc[:3950].values  # 使用 .values 轉換為 numpy 數組\n",
    "                # 後3950筆數據作為輸出\n",
    "                output_data = df.iloc[3950:4000].values\n",
    "                \n",
    "                train_inputs.append(input_data)\n",
    "                train_outputs.append(output_data)\n",
    "    \n",
    "    # 將結果轉換為 numpy 數組，方便後續使用\n",
    "    train_inputs = np.array(train_inputs)\n",
    "    train_outputs = np.array(train_outputs)\n",
    "    \n",
    "    return train_inputs, train_outputs\n",
    "\n",
    "# 分割數據\n",
    "train_inputs, train_outputs = split_data_for_training(resistor_data)\n",
    "\n",
    "# 查看數據形狀\n",
    "print(f\"Train inputs shape: {train_inputs.shape}\")\n",
    "print(f\"Train outputs shape: {train_outputs.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test target output: 0     442\n",
      "1     440\n",
      "2     436\n",
      "3     432\n",
      "4     429\n",
      "5     425\n",
      "6     421\n",
      "7     417\n",
      "8     414\n",
      "9     411\n",
      "10    408\n",
      "11    404\n",
      "12    401\n",
      "13    397\n",
      "14    394\n",
      "15    391\n",
      "16    388\n",
      "17    385\n",
      "18    381\n",
      "19    378\n",
      "20    375\n",
      "21    372\n",
      "22    369\n",
      "23    366\n",
      "24    363\n",
      "25    360\n",
      "26    357\n",
      "27    354\n",
      "28    351\n",
      "29    348\n",
      "30    345\n",
      "31    342\n",
      "32    339\n",
      "33    337\n",
      "34    334\n",
      "35    331\n",
      "36    328\n",
      "37    326\n",
      "38    324\n",
      "39    321\n",
      "40    319\n",
      "41    316\n",
      "42    314\n",
      "43    311\n",
      "44    309\n",
      "45    307\n",
      "46    304\n",
      "47    302\n",
      "48    300\n",
      "49    297\n",
      "Name: y01, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"test target output: {resistor_data['13']['a'].iloc[:50, 1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型\n",
    "##### 子模型1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResistancePredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResistancePredictor, self).__init__()\n",
    "        # 全連接層，用於將輸入轉換為單一電阻值\n",
    "        self.fc1 = nn.Linear(50*11 , 50)\n",
    "        self.fc2=nn.Linear(50,1)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.dropout(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x=self.dropout(x)\n",
    "        resistance = (self.fc2(x))\n",
    "        return resistance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 子模型2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class resmodel(nn.Module):\n",
    "    def __init__(self,input_size):\n",
    "        super(resmodel,self).__init__()\n",
    "        print('input_size_1',input_size)\n",
    "\n",
    "        self.l=nn.Linear(50+11,50)\n",
    "\n",
    "        self.b=nn.Linear(50+1,50)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "\n",
    "    def forward(self,x,id):\n",
    "        #log=self.dropout(id)\n",
    "        exp=self.l(id)\n",
    "        exp =5*torch.sigmoid(exp) # 限制输出范围\n",
    "        exp=torch.exp(exp)\n",
    "        #print(\"exp\",exp)\n",
    "        #b=self.dropout(id)\n",
    "        b=self.b(x)\n",
    "        b=torch.relu(b)\n",
    "\n",
    "        return exp+b\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 合併"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "class CompleteModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CompleteModel, self).__init__()\n",
    "\n",
    "        self.resistance_predictor = ResistancePredictor()\n",
    "        self.timeLong = 50\n",
    "        self.res = resmodel(input_size=25)\n",
    "    \n",
    "    def forward(self, bcd_input, target_input,id,j, mode='train',):\n",
    "        if mode == 'train':\n",
    "            resistance = self.resistance_predictor(bcd_input)\n",
    "\n",
    "            # 确保输出张量初始化时在正确的设备上\n",
    "            output = torch.empty(4000)\n",
    "\n",
    "            for i in range(0,3950,25):\n",
    "\n",
    "                temp = target_input[i:i+self.timeLong]\n",
    "                #print('temp size',temp.size())\n",
    "                # 将 resistance_predictor 拼接到 temp 中\n",
    "                temp = torch.cat((temp, resistance), dim=-1)\n",
    "                # 创建一个全为零的长度为 10 的一维张量\n",
    "                one_hot_tensor = torch.zeros(10)\n",
    "\n",
    "                # 将第 j-1 个位置的值设置为 1 (因为索引从 0 开始)\n",
    "                one_hot_tensor[int(j) - 1] = 1\n",
    "\n",
    "                temp_id=id[i:i+self.timeLong]\n",
    "                temp_id = torch.cat((temp_id, resistance), dim=-1)\n",
    "                temp_id = torch.cat((temp_id, one_hot_tensor.to(device)))\n",
    "\n",
    "                #print('temp',temp.shape)\n",
    "                # 通过 resmodel 模型预测\n",
    "                res = self.res(temp,temp_id)\n",
    "                res_temp=res[25:]\n",
    "                # 将结果拼接到 data 中\n",
    "\n",
    "                if i == 50:\n",
    "                    output[i+self.timeLong:i+self.timeLong+25] = res[:25]\n",
    "\n",
    "                elif i == 3975:\n",
    "                    output[i+self.timeLong:i+self.timeLong+25] = res[25:]\n",
    "                else:\n",
    "                    output[i+self.timeLong:i+self.timeLong+25] = (res[:25]+res_temp)/2\n",
    "\n",
    "            \n",
    "            output = output.to(device)\n",
    "            #print(\"output shape\",output.shape)\n",
    "            return output[50:]\n",
    "        \n",
    "        elif mode == 'test':\n",
    "            resistance = self.resistance_predictor(bcd_input)\n",
    "            \n",
    "            for i in range(50, 4000, 25):\n",
    "                temp = target_input[-self.timeLong:]\n",
    "                temp = torch.cat((temp, resistance), dim=-1)\n",
    "                one_hot_tensor = torch.zeros(10)\n",
    "\n",
    "\n",
    "                # 将第 j-1 个位置的值设置为 1 (因为索引从 0 开始)\n",
    "                one_hot_tensor[int(j) - 1] = 1\n",
    "\n",
    "                temp_id=id[i-self.timeLong:i]\n",
    "                temp_id = torch.cat((temp_id, resistance), dim=-1)\n",
    "                temp_id = torch.cat((temp_id, one_hot_tensor.to(device)))\n",
    "\n",
    "\n",
    "                res = self.res(temp,temp_id)\n",
    "                res_temp=res[25:]\n",
    "                if i == 50:\n",
    "                    target_input = torch.cat((target_input, res[:25]), dim=0)\n",
    "                elif i == 3975:\n",
    "                    target_input = torch.cat((target_input, res[25:]), dim=0)\n",
    "                else:\n",
    "                    target_input = torch.cat((target_input, (res[:25] + res_temp) / 2), dim=0)\n",
    "            #print(\"target_input shape\",target_input.shape)\n",
    "\n",
    "            return target_input[50:]\n",
    "\n",
    "        '''\n",
    "        for i in range(79):\n",
    "\n",
    "            temp = target_input[-self.timeLong:]\n",
    "            #print('temp size',temp.size())\n",
    "            # 将 resistance_predictor 拼接到 temp 中\n",
    "            \n",
    "            # 通过 resmodel 模型预测\n",
    "            res = self.res(temp)\n",
    "            #print('temp',temp)\n",
    "            # 将结果拼接到 data 中\n",
    "            target_input = torch.cat((target_input, res), dim=0)\n",
    "        return target_input[50:]\n",
    "        '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size_1 25\n",
      "CompleteModel(\n",
      "  (resistance_predictor): ResistancePredictor(\n",
      "    (fc1): Linear(in_features=550, out_features=50, bias=True)\n",
      "    (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (res): resmodel(\n",
      "    (l): Linear(in_features=61, out_features=50, bias=True)\n",
      "    (b): Linear(in_features=51, out_features=50, bias=True)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      ")\n",
      "Epoch 0, Loss: 183.03879108428956,test loss: 63.50257339477539\n",
      "time 17.144586324691772 sec net par\n",
      "Epoch 1, Loss: 181.105672899882,test loss: 63.38045883178711\n",
      "time 16.46148681640625 sec net par\n",
      "Epoch 2, Loss: 180.6038617769877,test loss: 63.25849380493164\n",
      "time 16.232955932617188 sec net par\n",
      "Epoch 3, Loss: 180.30575354894003,test loss: 63.15822792053223\n",
      "time 16.658860445022583 sec net par\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-60fff99b8f61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;31m# 反向傳播和優化\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[1;31m# 限制权重的大小，使用max-norm正则化\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "type='a'\n",
    "# 建立模型\n",
    "model = CompleteModel()\n",
    "device = torch.device(\"cuda:0\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 初始化网络参数\n",
    "for params in model.parameters():\n",
    "    init.normal_(params, mean=0, std=0.01)\n",
    "\n",
    "print(model)\n",
    "# 定義損失函數和優化器\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr= 1.15E-07, momentum=0.9)\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.1)       # 高动量\n",
    "\n",
    "# 假設有訓練數據 train_bcd_input, train_target_input, train_target_output\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.9, verbose=True)\n",
    "\n",
    "num_epochs=750\n",
    "# 使用一個簡單的訓練迴圈\n",
    "all_train_loss=[]\n",
    "all_test_loss=[]\n",
    "model=model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):  # 假設訓練100個epoch\n",
    "    start=time.time()\n",
    "\n",
    "    model.train()\n",
    "    trl=[]\n",
    "    for voltage in range(1, 13):     \n",
    "        voltage = str(voltage)  # 將數字轉換為字串\n",
    "    \n",
    "        input_1=resistor_data[voltage][type].iloc[:50].to_numpy().flatten()\n",
    "        input_1=torch.from_numpy(input_1).float()\n",
    "        input_1 = input_1.to(device)\n",
    "\n",
    "        id=resistor_data[voltage][type].iloc[:,0].to_numpy()\n",
    "        id=torch.from_numpy(id).float()\n",
    "        id = id.to(device)\n",
    "\n",
    "        for j in range(1,11):\n",
    "            \n",
    "            input_2=resistor_data[voltage][type].iloc[:,j].to_numpy()\n",
    "            input_2=torch.from_numpy(input_2).float()\n",
    "            input_2 = input_2.to(device)\n",
    "\n",
    "            target_out=resistor_data[voltage][type].iloc[50:,j].to_numpy()\n",
    "            target_out=torch.from_numpy(target_out).float()\n",
    "            target_out = target_out.to(device)\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 前向傳播\n",
    "            outputs = model(input_1, input_2,id,mode='train',j=j)\n",
    "            # 計算損失\n",
    "            # 调试输出形状\n",
    "            #print(f\"Epoch {epoch}, Voltage {voltage}, Iter {j}\")\n",
    "            #print(f\"outputs shape: {outputs.shape}, target_out shape: {target_out.shape}\")\n",
    "\n",
    "            # 确保形状匹配\n",
    "            if outputs.shape != target_out.shape:\n",
    "                raise ValueError(f\"Shape mismatch: outputs shape {outputs.shape}, target_out shape {target_out.shape}\")\n",
    "\n",
    "            # 计算损失\n",
    "            loss = torch.sqrt(criterion(outputs, target_out))\n",
    "\n",
    "            # 调试输出 `grad_fn`\n",
    "            #print(f\"outputs grad_fn: {outputs.grad_fn}\")\n",
    "\n",
    "\n",
    "\n",
    "            # 反向傳播和優化\n",
    "            loss.backward()\n",
    "\n",
    "            # 限制权重的大小，使用max-norm正则化\n",
    "            for param in model.parameters():\n",
    "                nn.utils.clip_grad_norm_(param, max_norm=5.0)\n",
    "        \n",
    "\n",
    "            optimizer.step()\n",
    "            trl.append(loss.item())\n",
    "\n",
    "            \n",
    "    all_train_loss.append(np.mean(trl))\n",
    "    scheduler.step(np.mean(trl))\n",
    "\n",
    "    #test\n",
    "    model.eval()\n",
    "\n",
    "    tel=[]\n",
    "    test_input_1=resistor_data['13'][type].iloc[:50].to_numpy().flatten()\n",
    "    test_input_1=torch.from_numpy(test_input_1).float()\n",
    "    test_input_1 = test_input_1.to(device)\n",
    "\n",
    "    test_id=resistor_data['13'][type].iloc[:,0].to_numpy()\n",
    "    test_id=torch.from_numpy(test_id).float()\n",
    "    test_id = test_id.to(device)\n",
    "\n",
    "    for j in range(1,11):\n",
    "        test_input_2=resistor_data['13'][type].iloc[:50,j].to_numpy()\n",
    "        test_input_2=torch.from_numpy(test_input_2).float()\n",
    "        test_input_2 = test_input_2.to(device)\n",
    "\n",
    "\n",
    "        test_output=model(test_input_1,test_input_2,id=test_id,mode='test',j=j)\n",
    "        \n",
    "        test_target_out=resistor_data['13'][type].iloc[50:,j].to_numpy()\n",
    "        test_target_out=torch.from_numpy(test_target_out).float()\n",
    "        test_target_out = test_target_out.to(device)\n",
    "\n",
    "\n",
    "        test_loss = torch.sqrt(criterion(test_output, test_target_out))\n",
    "        tel.append(test_loss.item())\n",
    "    all_test_loss.append(np.mean(tel))\n",
    "\n",
    "    \n",
    "    \n",
    "    print(f'Epoch {epoch}, Loss: {np.mean(trl)},test loss: {np.mean(tel)}')\n",
    "    print('time',time.time()-start,'sec','net par')\n",
    "\n",
    "#print(\"all_train_loss\",all_train_loss)\n",
    "x=np.linspace(start=0,stop=num_epochs,num=len(all_train_loss))\n",
    "#print(\"x\",x)\n",
    "\n",
    "plt.plot(x,all_train_loss, 'r:')\n",
    "plt.plot(x,all_test_loss, 'b:')\n",
    "plt.legend(['train loss','test loss'])\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.yscale('log')          # log y-axis\n",
    "\n",
    "plt.show()  \n",
    "\n",
    "    \n",
    "print('outputs',outputs)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "'''\n",
    "timeLong=50\n",
    "for epoch in range(10000):\n",
    "    all_outputs=train_target_input\n",
    "    temp = train_target_input[-timeLong:]\n",
    "\n",
    "    for i in range(3950):\n",
    "        temp = temp[-timeLong:]\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #print('temp size',temp.size())\n",
    "        # 前向傳播\n",
    "        outputs = model(temp)\n",
    "        \n",
    "        # 計算損失\n",
    "        #print('outputs',outputs.size())\n",
    "        #print('train_target_output[i]',train_target_output[i].size())\n",
    "        train_target_output_num = torch.tensor([train_target_output[i].item()])\n",
    "\n",
    "        loss = torch.sqrt(criterion(outputs, train_target_output_num))\n",
    "        \n",
    "        # 反向傳播和優化\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        temp = torch.cat((temp, outputs), dim=0)\n",
    "        all_outputs = torch.cat((all_outputs, outputs), dim=0)\n",
    "\n",
    "\n",
    "    # 計算損失\n",
    "    #print('all_outputs size',all_outputs[50:].size())\n",
    "    #print(\"train_target_output\",train_target_output.size())\n",
    "    all_loss = torch.sqrt(criterion(all_outputs[50:], train_target_output))\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, all_Loss: {all_loss.item()}')\n",
    "\n",
    "print('outputs',all_outputs[50:])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size_1 25\n",
      "CompleteModel(\n",
      "  (resistance_predictor): ResistancePredictor(\n",
      "    (fc1): Linear(in_features=550, out_features=50, bias=True)\n",
      "    (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (res): resmodel(\n",
      "    (l): Linear(in_features=61, out_features=50, bias=True)\n",
      "    (b): Linear(in_features=51, out_features=50, bias=True)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1557cbfa318e4d9ab9f562a99db58de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n",
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 1.18E-07\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "\n",
    "class ResistorDataset(Dataset):\n",
    "    def __init__(self, resistor_data, voltages, type):\n",
    "        self.resistor_data = resistor_data\n",
    "        self.voltages = voltages\n",
    "        self.type = type\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.voltages) * 11  # 每个电压有11个input_2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        voltage_idx = idx // 11  # 计算电压索引\n",
    "        j = idx % 11  # 计算 j 索引\n",
    "\n",
    "        voltage = str(self.voltages[voltage_idx])\n",
    "        input_1 = self.resistor_data[voltage][self.type].iloc[:50].to_numpy().flatten()\n",
    "        input_2 = self.resistor_data[voltage][self.type].iloc[:, j].to_numpy()\n",
    "        target = self.resistor_data[voltage][self.type].iloc[50:, j].to_numpy()\n",
    "\n",
    "        input_1 = torch.from_numpy(input_1).float()\n",
    "        input_2 = torch.from_numpy(input_2).float()\n",
    "        target = torch.from_numpy(target).float()\n",
    "\n",
    "        id=resistor_data[voltage][type].iloc[:,0].to_numpy()\n",
    "        id=torch.from_numpy(id).float()\n",
    "        id = id.to(device)\n",
    "\n",
    "        #print(\"input_2\",input_2)\n",
    "        return input_1, input_2,id,j,target\n",
    "\n",
    "\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "class CustomLRFinder(LRFinder):\n",
    "    def _move_to_device(self, tensor, non_blocking=True):\n",
    "        return tensor.to(self.device, non_blocking=non_blocking)\n",
    "    \n",
    "    def _train_batch(self, train_iter, accumulation_steps, non_blocking_transfer=True):\n",
    "        self.model.train()\n",
    "        total_loss = None\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        for i in range(accumulation_steps):\n",
    "            try:\n",
    "                inputs, target_input = next(train_iter)\n",
    "            except StopIteration:\n",
    "                return -1\n",
    "\n",
    "            # 解包 inputs\n",
    "            inputs1, inputs2,id,j = inputs\n",
    "           \n",
    "            inputs1=inputs1.view(-1)\n",
    "            inputs2=inputs2.view(-1)\n",
    "            j=j.view(-1)\n",
    "            #print(\"j\",j)\n",
    "            id=id.view(-1)\n",
    "            target_input=target_input.view(-1)\n",
    "            #print(\"inputs1 s\",inputs1.shape)\n",
    "            #print(\"inputs2 s\",inputs2.shape)\n",
    "            # 移動數據到設備上\n",
    "            inputs1 = self._move_to_device(inputs1, non_blocking=non_blocking_transfer)\n",
    "            inputs2 = self._move_to_device(inputs2, non_blocking=non_blocking_transfer)\n",
    "            target_input = self._move_to_device(target_input, non_blocking=non_blocking_transfer)\n",
    "\n",
    "            # 前向傳播\n",
    "            outputs = self.model(inputs1, inputs2,id,mode='train',j=j)\n",
    "            loss = self.criterion(outputs, target_input)\n",
    "\n",
    "            # 平均損失\n",
    "            loss /= accumulation_steps\n",
    "\n",
    "            # 反向傳播\n",
    "            loss.backward()\n",
    "\n",
    "            if total_loss is None:\n",
    "                total_loss = loss.detach().item()\n",
    "            else:\n",
    "                total_loss += loss.detach().item()\n",
    "\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "# Initialize and wrap the model\n",
    "model = CompleteModel()\n",
    "\n",
    "# Define voltages and create dataset and dataloaders\n",
    "voltages = list(range(1, 14))  # 从1到13的电压值\n",
    "type = 'a'\n",
    "\n",
    "train_dataset = ResistorDataset(resistor_data, voltages=voltages[:-1], type=type)  # 使用1-12的电压作为训练集\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "'''\n",
    "for input_1, input_2,t in train_loader:\n",
    "    print(\"input_1\",input_1)\n",
    "    print(\"input_2\",input_2)\n",
    "    print(\"t\",t)\n",
    "'''\n",
    "test_dataset = ResistorDataset(resistor_data, voltages=[13], type=type)  # 使用13的电压作为测试集\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Initialize model parameters\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(model)\n",
    "for params in model.parameters():\n",
    "    #print(params)\n",
    "    init.normal_(params, mean=0, std=0.01)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "# Use torch-lr-finder to find optimal learning rate\n",
    "# 使用自定義的 LRFinder\n",
    "class DataLoaderWrapper(torch.utils.data.DataLoader):\n",
    "    def __iter__(self):\n",
    "        for idx, batch in enumerate(super().__iter__()):\n",
    "            # 構建符合 (inputs, targets) 結構的批次數據\n",
    "            inputs = (batch[0], batch[1], batch[2], batch[3])\n",
    "            targets = batch[4]\n",
    "            \n",
    "            #print(f\"DataLoaderWrapper output - Index: {idx}, Inputs Length: {len(inputs)}, Targets Shape: {targets.shape}\")\n",
    "            \n",
    "            yield inputs, targets\n",
    "\n",
    "lr_finder = CustomLRFinder(model, optimizer, criterion, device=device)\n",
    "lr_finder.range_test(DataLoaderWrapper(test_dataset),start_lr=1e-7, end_lr=1e-1, num_iter=1000, smooth_f=0.05,diverge_th=100)\n",
    "#lr_finder.range_test(test_loader, end_lr=1, num_iter=100)\n",
    "lr_finder.plot()  # 显示损失函数与学习率的关系图\n",
    "lr_finder.reset()  # 重置模型和优化器到初始状态\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
