{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voltage: 1\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Voltage: 10\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Voltage: 11\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Voltage: 12\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Voltage: 13\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Voltage: 2\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Voltage: 3\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Voltage: 4\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Voltage: 5\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Voltage: 6\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Voltage: 7\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Voltage: 8\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Voltage: 9\n",
      "  Resistor: a, Data shape: (4000, 11)\n",
      "  Resistor: b, Data shape: (4000, 11)\n",
      "  Resistor: c, Data shape: (4000, 11)\n",
      "  Resistor: d, Data shape: (4000, 11)\n",
      "Train inputs shape: (52, 3950, 11)\n",
      "Train outputs shape: (52, 50, 11)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def load_resistor_data(data_dir):\n",
    "    # 創建一個字典來保存所有電阻和電壓的數據\n",
    "    data = {}\n",
    "    \n",
    "    # 遍歷每個電壓資料夾\n",
    "    for voltage_folder in os.listdir(data_dir):\n",
    "        voltage_path = os.path.join(data_dir, voltage_folder)\n",
    "        if os.path.isdir(voltage_path):\n",
    "            # 創建一個子字典來保存這個電壓下的所有電阻數據\n",
    "            data[voltage_folder] = {}\n",
    "            \n",
    "            # 遍歷該電壓資料夾中的所有電阻文件\n",
    "            for resistor_file in os.listdir(voltage_path):\n",
    "                resistor_path = os.path.join(voltage_path, resistor_file)\n",
    "                if resistor_file.endswith('.csv'):\n",
    "                    # 讀取CSV文件到一個DataFrame中\n",
    "                    resistor_data = pd.read_csv(resistor_path)\n",
    "                    \n",
    "                    # 將數據存入字典中\n",
    "                    resistor_name = os.path.splitext(resistor_file)[0]  # 獲取文件名（去掉擴展名）\n",
    "                    data[voltage_folder][resistor_name] = resistor_data\n",
    "                    \n",
    "    return data\n",
    "\n",
    "# 假設數據位於 /data/ 目錄中\n",
    "data_dir = 'C:\\\\Users\\\\walter\\\\OneDrive\\\\桌面\\\\收集\\\\2024大數據競賽\\\\2024-pre-train'\n",
    "resistor_data = load_resistor_data(data_dir)\n",
    "\n",
    "# 查看讀取的數據結構\n",
    "for voltage, resistors in resistor_data.items():\n",
    "    print(f\"Voltage: {voltage}\")\n",
    "    for resistor, df in resistors.items():\n",
    "        print(f\"  Resistor: {resistor}, Data shape: {df.shape}\")\n",
    "\n",
    "#print(resistor_data['1']['a'])\n",
    "import numpy as np\n",
    "\n",
    "def split_data_for_training(resistor_data):\n",
    "    train_inputs = []\n",
    "    train_outputs = []\n",
    "    \n",
    "    # 遍歷每個電壓資料夾\n",
    "    for voltage, resistors in resistor_data.items():\n",
    "        for resistor, df in resistors.items():\n",
    "            # 檢查數據是否有足夠的行數\n",
    "            if len(df) >= 4000:\n",
    "                # 前50筆數據作為輸入\n",
    "                input_data = df.iloc[:3950].values  # 使用 .values 轉換為 numpy 數組\n",
    "                # 後3950筆數據作為輸出\n",
    "                output_data = df.iloc[3950:4000].values\n",
    "                \n",
    "                train_inputs.append(input_data)\n",
    "                train_outputs.append(output_data)\n",
    "    \n",
    "    # 將結果轉換為 numpy 數組，方便後續使用\n",
    "    train_inputs = np.array(train_inputs)\n",
    "    train_outputs = np.array(train_outputs)\n",
    "    \n",
    "    return train_inputs, train_outputs\n",
    "\n",
    "# 分割數據\n",
    "train_inputs, train_outputs = split_data_for_training(resistor_data)\n",
    "\n",
    "# 查看數據形狀\n",
    "print(f\"Train inputs shape: {train_inputs.shape}\")\n",
    "print(f\"Train outputs shape: {train_outputs.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test target output: 0     442\n",
      "1     440\n",
      "2     436\n",
      "3     432\n",
      "4     429\n",
      "5     425\n",
      "6     421\n",
      "7     417\n",
      "8     414\n",
      "9     411\n",
      "10    408\n",
      "11    404\n",
      "12    401\n",
      "13    397\n",
      "14    394\n",
      "15    391\n",
      "16    388\n",
      "17    385\n",
      "18    381\n",
      "19    378\n",
      "20    375\n",
      "21    372\n",
      "22    369\n",
      "23    366\n",
      "24    363\n",
      "25    360\n",
      "26    357\n",
      "27    354\n",
      "28    351\n",
      "29    348\n",
      "30    345\n",
      "31    342\n",
      "32    339\n",
      "33    337\n",
      "34    334\n",
      "35    331\n",
      "36    328\n",
      "37    326\n",
      "38    324\n",
      "39    321\n",
      "40    319\n",
      "41    316\n",
      "42    314\n",
      "43    311\n",
      "44    309\n",
      "45    307\n",
      "46    304\n",
      "47    302\n",
      "48    300\n",
      "49    297\n",
      "Name: y01, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"test target output: {resistor_data['13']['a'].iloc[:50, 1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型\n",
    "##### 子模型1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResistancePredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResistancePredictor, self).__init__()\n",
    "        # 全連接層，用於將輸入轉換為單一電阻值\n",
    "        self.fc1 = nn.Linear(50*11 , 50)\n",
    "        self.fc2=nn.Linear(50,1)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.dropout(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x=self.dropout(x)\n",
    "        resistance = (self.fc2(x))\n",
    "        return resistance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 子模型2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class resmodel(nn.Module):\n",
    "    def __init__(self,input_size):\n",
    "        super(resmodel,self).__init__()\n",
    "        print('input_size_1',input_size)\n",
    "\n",
    "        self.res=nn.Linear(50+11,50)\n",
    "        self.res2=nn.Linear(50,50)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.dropout(x)\n",
    "        x=torch.relu(self.res(x))\n",
    "        x=self.dropout(x)\n",
    "        x=(self.res2(x))\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 合併"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "class CompleteModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CompleteModel, self).__init__()\n",
    "\n",
    "        self.resistance_predictor = ResistancePredictor()\n",
    "        self.timeLong = 50\n",
    "        self.res = resmodel(input_size=25)\n",
    "    \n",
    "    def forward(self, bcd_input, target_input,j, mode='train',):\n",
    "        if mode == 'train':\n",
    "            resistance = self.resistance_predictor(bcd_input)\n",
    "\n",
    "            # 确保输出张量初始化时在正确的设备上\n",
    "            output = torch.empty(4000)\n",
    "\n",
    "            for i in range(0,3950,25):\n",
    "\n",
    "                temp = target_input[i:i+self.timeLong]\n",
    "                #print('temp size',temp.size())\n",
    "                # 将 resistance_predictor 拼接到 temp 中\n",
    "                temp = torch.cat((temp, resistance), dim=-1)\n",
    "                # 创建一个全为零的长度为 10 的一维张量\n",
    "                one_hot_tensor = torch.zeros(10)\n",
    "\n",
    "                # 将第 j-1 个位置的值设置为 1 (因为索引从 0 开始)\n",
    "                one_hot_tensor[j - 1] = 1\n",
    "                temp = torch.cat((temp, one_hot_tensor.to(device)))\n",
    "\n",
    "                #print('temp',temp.shape)\n",
    "                # 通过 resmodel 模型预测\n",
    "                res = self.res(temp)\n",
    "                res_temp=res[25:]\n",
    "                # 将结果拼接到 data 中\n",
    "\n",
    "                if i == 50:\n",
    "                    output[i+self.timeLong:i+self.timeLong+25] = res[:25]\n",
    "\n",
    "                elif i == 3975:\n",
    "                    output[i+self.timeLong:i+self.timeLong+25] = res[25:]\n",
    "                else:\n",
    "                    output[i+self.timeLong:i+self.timeLong+25] = (res[:25]+res_temp)/2\n",
    "\n",
    "            \n",
    "            output = output.to(device)\n",
    "            #print(\"output shape\",output.shape)\n",
    "            return output[50:]\n",
    "        \n",
    "        elif mode == 'test':\n",
    "            resistance = self.resistance_predictor(bcd_input)\n",
    "            \n",
    "            for i in range(50, 4000, 25):\n",
    "                temp = target_input[-self.timeLong:]\n",
    "                temp = torch.cat((temp, resistance), dim=-1)\n",
    "                one_hot_tensor = torch.zeros(10)\n",
    "\n",
    "                # 将第 j-1 个位置的值设置为 1 (因为索引从 0 开始)\n",
    "                one_hot_tensor[j - 1] = 1\n",
    "                temp = torch.cat((temp, one_hot_tensor.to(device)))\n",
    "                res = self.res(temp)\n",
    "                res_temp=res[:25]\n",
    "                if i == 50:\n",
    "                    target_input = torch.cat((target_input, res[:25]), dim=0)\n",
    "                elif i == 3975:\n",
    "                    target_input = torch.cat((target_input, res[25:]), dim=0)\n",
    "                else:\n",
    "                    target_input = torch.cat((target_input, (res[:25] + res_temp) / 2), dim=0)\n",
    "            #print(\"target_input shape\",target_input.shape)\n",
    "\n",
    "            return target_input[50:]\n",
    "\n",
    "        '''\n",
    "        for i in range(79):\n",
    "\n",
    "            temp = target_input[-self.timeLong:]\n",
    "            #print('temp size',temp.size())\n",
    "            # 将 resistance_predictor 拼接到 temp 中\n",
    "            \n",
    "            # 通过 resmodel 模型预测\n",
    "            res = self.res(temp)\n",
    "            #print('temp',temp)\n",
    "            # 将结果拼接到 data 中\n",
    "            target_input = torch.cat((target_input, res), dim=0)\n",
    "        return target_input[50:]\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size_1 25\n",
      "CompleteModel(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 3, kernel_size=(5, 1), stride=(1, 1))\n",
      "    (1): Tanh()\n",
      "    (2): Conv2d(3, 3, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (3): Tanh()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(3, 3, kernel_size=(6, 6), stride=(1, 1))\n",
      "    (6): Tanh()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (resistance_predictor): ResistancePredictor(\n",
      "    (fc1): Linear(in_features=550, out_features=50, bias=True)\n",
      "    (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (res): resmodel(\n",
      "    (res): Linear(in_features=61, out_features=50, bias=True)\n",
      "    (res2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0439304d03054193be5ee9b0d828ae70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n",
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 1.02E-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "\n",
    "class ResistorDataset(Dataset):\n",
    "    def __init__(self, resistor_data, voltages, type):\n",
    "        self.resistor_data = resistor_data\n",
    "        self.voltages = voltages\n",
    "        self.type = type\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.voltages) * 11  # 每个电压有11个input_2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        voltage_idx = idx // 11  # 计算电压索引\n",
    "        j = idx % 11  # 计算 j 索引\n",
    "\n",
    "        voltage = str(self.voltages[voltage_idx])\n",
    "        input_1 = self.resistor_data[voltage][self.type].iloc[:50].to_numpy().flatten()\n",
    "        input_2 = self.resistor_data[voltage][self.type].iloc[:, j].to_numpy()\n",
    "        target_input = self.resistor_data[voltage][self.type].iloc[50:, j].to_numpy()\n",
    "\n",
    "        input_1 = torch.from_numpy(input_1).float()\n",
    "        input_2 = torch.from_numpy(input_2).float()\n",
    "        target_input = torch.from_numpy(target_input).float()\n",
    "\n",
    "        #print(\"input_2\",input_2)\n",
    "        return input_1, input_2,j,target_input\n",
    "\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "class CustomLRFinder(LRFinder):\n",
    "    def _move_to_device(self, tensor, non_blocking=True):\n",
    "        return tensor.to(self.device, non_blocking=non_blocking)\n",
    "    \n",
    "    def _train_batch(self, train_iter, accumulation_steps, non_blocking_transfer=True):\n",
    "        self.model.train()\n",
    "        total_loss = None\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        for i in range(accumulation_steps):\n",
    "            try:\n",
    "                inputs, target_input = next(train_iter)\n",
    "            except StopIteration:\n",
    "                return -1\n",
    "\n",
    "            # 解包 inputs\n",
    "            inputs1, inputs2,j = inputs\n",
    "           \n",
    "            inputs1=inputs1.view(-1)\n",
    "            inputs2=inputs2.view(-1)\n",
    "            j=j.view(-1)\n",
    "\n",
    "            #print(\"inputs1 s\",inputs1.shape)\n",
    "            #print(\"inputs2 s\",inputs2.shape)\n",
    "            # 移動數據到設備上\n",
    "            inputs1 = self._move_to_device(inputs1, non_blocking=non_blocking_transfer)\n",
    "            inputs2 = self._move_to_device(inputs2, non_blocking=non_blocking_transfer)\n",
    "            target_input = self._move_to_device(target_input, non_blocking=non_blocking_transfer)\n",
    "\n",
    "            # 前向傳播\n",
    "            outputs = self.model(inputs1, inputs2,j)\n",
    "            loss = self.criterion(outputs, target_input)\n",
    "\n",
    "            # 平均損失\n",
    "            loss /= accumulation_steps\n",
    "\n",
    "            # 反向傳播\n",
    "            loss.backward()\n",
    "\n",
    "            if total_loss is None:\n",
    "                total_loss = loss.detach().item()\n",
    "            else:\n",
    "                total_loss += loss.detach().item()\n",
    "\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "# Initialize and wrap the model\n",
    "model = CompleteModel()\n",
    "\n",
    "# Define voltages and create dataset and dataloaders\n",
    "voltages = list(range(1, 14))  # 从1到13的电压值\n",
    "type = 'a'\n",
    "\n",
    "train_dataset = ResistorDataset(resistor_data, voltages=voltages[:-1], type=type)  # 使用1-12的电压作为训练集\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "'''\n",
    "for input_1, input_2,t in train_loader:\n",
    "    print(\"input_1\",input_1)\n",
    "    print(\"input_2\",input_2)\n",
    "    print(\"t\",t)\n",
    "'''\n",
    "test_dataset = ResistorDataset(resistor_data, voltages=[13], type=type)  # 使用13的电压作为测试集\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Initialize model parameters\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(model)\n",
    "for params in model.parameters():\n",
    "    #print(params)\n",
    "    init.normal_(params, mean=0, std=0.01)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "# Use torch-lr-finder to find optimal learning rate\n",
    "# 使用自定義的 LRFinder\n",
    "class DataLoaderWrapper(torch.utils.data.DataLoader):\n",
    "    def __iter__(self):\n",
    "        for idx, batch in enumerate(super().__iter__()):\n",
    "            # 構建符合 (inputs, targets) 結構的批次數據\n",
    "            inputs = (batch[0], batch[1], batch[2])\n",
    "            targets = batch[3]\n",
    "            \n",
    "            #print(f\"DataLoaderWrapper output - Index: {idx}, Inputs Length: {len(inputs)}, Targets Shape: {targets.shape}\")\n",
    "            \n",
    "            yield inputs, targets\n",
    "\n",
    "lr_finder = CustomLRFinder(model, optimizer, criterion, device=device)\n",
    "lr_finder.range_test(DataLoaderWrapper(test_dataset),start_lr=1e-6, end_lr=1, num_iter=10000, smooth_f=0.05,diverge_th=100)\n",
    "#lr_finder.range_test(test_loader, end_lr=1, num_iter=100)\n",
    "lr_finder.plot()  # 显示损失函数与学习率的关系图\n",
    "lr_finder.reset()  # 重置模型和优化器到初始状态\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size_1 25\n",
      "CompleteModel(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 3, kernel_size=(5, 1), stride=(1, 1))\n",
      "    (1): Tanh()\n",
      "    (2): Conv2d(3, 3, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (3): Tanh()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(3, 3, kernel_size=(6, 6), stride=(1, 1))\n",
      "    (6): Tanh()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (resistance_predictor): ResistancePredictor(\n",
      "    (fc1): Linear(in_features=550, out_features=50, bias=True)\n",
      "    (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (res): resmodel(\n",
      "    (res): Linear(in_features=61, out_features=50, bias=True)\n",
      "    (res2): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      ")\n",
      "Epoch 0, Loss: 237.02336139678954,test loss: 61.58205223083496\n",
      "time 15.21906065940857 sec net par\n",
      "Epoch 1, Loss: 236.52747732798258,test loss: 61.55807380676269\n",
      "time 14.959295988082886 sec net par\n",
      "Epoch 2, Loss: 235.9387092590332,test loss: 61.52947731018067\n",
      "time 14.41152024269104 sec net par\n",
      "Epoch 3, Loss: 235.1920418103536,test loss: 61.4940601348877\n",
      "time 15.871416091918945 sec net par\n",
      "Epoch 4, Loss: 234.2671690940857,test loss: 61.45152740478515\n",
      "time 15.563475131988525 sec net par\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-0480763f1895>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;31m# 反向傳播和優化\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[1;31m# 限制权重的大小，使用max-norm正则化\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "type='a'\n",
    "# 建立模型\n",
    "model = CompleteModel()\n",
    "device = torch.device(\"cuda:0\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 初始化网络参数\n",
    "for params in model.parameters():\n",
    "    init.normal_(params, mean=0, std=0.01)\n",
    "\n",
    "print(model)\n",
    "# 定義損失函數和優化器\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr= 3.35E-06, momentum=0.9)\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.1)       # 高动量\n",
    "\n",
    "# 假設有訓練數據 train_bcd_input, train_target_input, train_target_output\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.8, verbose=True)\n",
    "\n",
    "num_epochs=750\n",
    "# 使用一個簡單的訓練迴圈\n",
    "all_train_loss=[]\n",
    "all_test_loss=[]\n",
    "model=model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):  # 假設訓練100個epoch\n",
    "    start=time.time()\n",
    "\n",
    "    model.train()\n",
    "    trl=[]\n",
    "    for voltage in range(1, 13):     \n",
    "        voltage = str(voltage)  # 將數字轉換為字串\n",
    "    \n",
    "        input_1=resistor_data[voltage][type].iloc[:50].to_numpy().flatten()\n",
    "        input_1=torch.from_numpy(input_1).float()\n",
    "        input_1 = input_1.to(device)\n",
    "\n",
    "        for j in range(1,11):\n",
    "            \n",
    "            input_2=resistor_data[voltage][type].iloc[:,j].to_numpy()\n",
    "            input_2=torch.from_numpy(input_2).float()\n",
    "            input_2 = input_2.to(device)\n",
    "\n",
    "            target_out=resistor_data[voltage][type].iloc[50:,j].to_numpy()\n",
    "            target_out=torch.from_numpy(target_out).float()\n",
    "            target_out = target_out.to(device)\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 前向傳播\n",
    "            outputs = model(input_1, input_2,mode='train',j=j)\n",
    "            # 計算損失\n",
    "            # 调试输出形状\n",
    "            #print(f\"Epoch {epoch}, Voltage {voltage}, Iter {j}\")\n",
    "            #print(f\"outputs shape: {outputs.shape}, target_out shape: {target_out.shape}\")\n",
    "\n",
    "            # 确保形状匹配\n",
    "            if outputs.shape != target_out.shape:\n",
    "                raise ValueError(f\"Shape mismatch: outputs shape {outputs.shape}, target_out shape {target_out.shape}\")\n",
    "\n",
    "            # 计算损失\n",
    "            loss = torch.sqrt(criterion(outputs, target_out))\n",
    "\n",
    "            # 调试输出 `grad_fn`\n",
    "            #print(f\"outputs grad_fn: {outputs.grad_fn}\")\n",
    "\n",
    "\n",
    "\n",
    "            # 反向傳播和優化\n",
    "            loss.backward()\n",
    "\n",
    "            # 限制权重的大小，使用max-norm正则化\n",
    "            for param in model.parameters():\n",
    "                nn.utils.clip_grad_norm_(param, max_norm=5.0)\n",
    "        \n",
    "\n",
    "            optimizer.step()\n",
    "            trl.append(loss.item())\n",
    "\n",
    "            \n",
    "    all_train_loss.append(np.mean(trl))\n",
    "    scheduler.step(np.mean(trl))\n",
    "\n",
    "    #test\n",
    "    model.eval()\n",
    "\n",
    "    tel=[]\n",
    "    test_input_1=resistor_data['13'][type].iloc[:50].to_numpy().flatten()\n",
    "    test_input_1=torch.from_numpy(test_input_1).float()\n",
    "    test_input_1 = test_input_1.to(device)\n",
    "\n",
    "    for j in range(1,11):\n",
    "        test_input_2=resistor_data['13'][type].iloc[:50,j].to_numpy()\n",
    "        test_input_2=torch.from_numpy(test_input_2).float()\n",
    "        test_input_2 = test_input_2.to(device)\n",
    "\n",
    "\n",
    "        test_output=model(test_input_1,test_input_2,mode='test',j=j)\n",
    "        \n",
    "        test_target_out=resistor_data['13'][type].iloc[50:,j].to_numpy()\n",
    "        test_target_out=torch.from_numpy(test_target_out).float()\n",
    "        test_target_out = test_target_out.to(device)\n",
    "\n",
    "\n",
    "        test_loss = torch.sqrt(criterion(test_output, test_target_out))\n",
    "        tel.append(test_loss.item())\n",
    "    all_test_loss.append(np.mean(tel))\n",
    "\n",
    "    \n",
    "    \n",
    "    print(f'Epoch {epoch}, Loss: {np.mean(trl)},test loss: {np.mean(tel)}')\n",
    "    print('time',time.time()-start,'sec','net par')\n",
    "\n",
    "#print(\"all_train_loss\",all_train_loss)\n",
    "x=np.linspace(start=0,stop=num_epochs,num=len(all_train_loss))\n",
    "#print(\"x\",x)\n",
    "\n",
    "plt.plot(x,all_train_loss, 'r:')\n",
    "plt.plot(x,all_test_loss, 'b:')\n",
    "plt.legend(['train loss','test loss'])\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.yscale('log')          # log y-axis\n",
    "\n",
    "plt.show()  \n",
    "\n",
    "    \n",
    "print('outputs',outputs)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "'''\n",
    "timeLong=50\n",
    "for epoch in range(10000):\n",
    "    all_outputs=train_target_input\n",
    "    temp = train_target_input[-timeLong:]\n",
    "\n",
    "    for i in range(3950):\n",
    "        temp = temp[-timeLong:]\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #print('temp size',temp.size())\n",
    "        # 前向傳播\n",
    "        outputs = model(temp)\n",
    "        \n",
    "        # 計算損失\n",
    "        #print('outputs',outputs.size())\n",
    "        #print('train_target_output[i]',train_target_output[i].size())\n",
    "        train_target_output_num = torch.tensor([train_target_output[i].item()])\n",
    "\n",
    "        loss = torch.sqrt(criterion(outputs, train_target_output_num))\n",
    "        \n",
    "        # 反向傳播和優化\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        temp = torch.cat((temp, outputs), dim=0)\n",
    "        all_outputs = torch.cat((all_outputs, outputs), dim=0)\n",
    "\n",
    "\n",
    "    # 計算損失\n",
    "    #print('all_outputs size',all_outputs[50:].size())\n",
    "    #print(\"train_target_output\",train_target_output.size())\n",
    "    all_loss = torch.sqrt(criterion(all_outputs[50:], train_target_output))\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, all_Loss: {all_loss.item()}')\n",
    "\n",
    "print('outputs',all_outputs[50:])\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
